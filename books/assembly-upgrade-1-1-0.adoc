// Module included in the following assemblies:
//
// master.adoc

[id='assembly-upgrade-1-1-0-{context}']

= Upgrading an {ProductName} cluster from 1.0.0 to 1.1.0

This chapter describes how to upgrade {ProductName} on Red Hat Enterprise Linux to version 1.1.0, which is based on Apache Kafka 2.1.1. No cluster downtime is required. 

Although AMQ Streams 1.1.0 and Kafka 2.1.1 are both minor releases, the Kafka protocol has changed since Kafka 2.0.0 was released (in particular, the message format version and inter-broker protocol version are both now at version 2.1). Therefore, the upgrade process involves configuration changes to your existing Kafka brokers and code changes to client applications (consumers and producers).

Upgrading to {ProductName} 1.1.0 is a two-stage process:

. First, you upgrade your {ProductName} installation to version 1.1.0, and then conduct performance testing.
. Next, you upgrade all Kafka brokers and clients to Kafka 2.1.1. To avoid cluster downtime, this stage involves multiple procedures.

The remainder of this chapter is divided into six separate procedures; Red Hat recommends that you complete them in the order shown.

//ADD CROSS REFERENCES TO THE OUTLINE TOC//

. Upgrading to {ProductName} 1.1.0
. Upgrading Kafka brokers and client applications to Kafka 2.1.1
.. Downgrading Kafka brokers to the previous inter-broker protocol and message format versions
.. Updating Kafka brokers to the new inter-broker protocol version
.. Upgrading client applications to the new Kafka version
.. Updating Kafka brokers to the new message format version

.Prerequisites
* You have read the link:https://access.redhat.com/documentation/en-us/red_hat_amq/7.2/html-single/amq_streams_1.1.0_on_red_hat_enterprise_linux_rhel_release_notes[{ProductName} 1.1.0 on Red Hat Enterprise Linux Release Notes].
* You are logged in to Red Hat Enterprise Linux as the `kafka` user that was created during the initial installation of {ProductName}.

= Upgrading to {ProductName} 1.1.0

To upgrade your cluster to {ProductName} 1.1.0, download and extract the *Red Hat AMQ Streams 1.1.0* archive from the Red Hat Customer Portal. 

.Prerequisites
* {ProductName} 1.0 is installed. For instructions, see xref:proc-installing-amq-streams-{context}[Installing {ProductName}].

.Procedure

. Download the *Red Hat AMQ Streams 1.1.0* archive from the {ReleaseDownload110} area of the Customer Portal.
+
NOTE: If prompted, log in to your Red Hat account. Make sure that *1.1.0* is selected in the *Version* drop-down list.
+
. On the command line, make sure that the System Security Services Daemon (SSSD) is running.
+
[source,shell,subs=+quotes]
----
sudo sssd
----

. Change the owner of the archive to the `kafka` user. In this example, the archive was downloaded to the Downloads directory.
+
[source,shell,subs=+quotes]
----
cd Downloads 
sudo chown kafka:kafka amq-streams-1.1.0-bin.zip
----

. Move the archive to the `/opt/kafka` directory that was created during the installation of {ProductName} 1.0.
+
[source,shell,subs=+quotes]
----
sudo mv amq-streams-1.1.0-bin.zip /opt/kafka
----

. Change the current user ID to the `kafka` user and enter the password.
+
[source,shell,subs=+quotes]
----
su - kafka
Password: ********
----

. As the `kafka` user, extract the contents of the {ProductName} 1.1.0 archive. This example uses the `unzip` command.
+
[source,shell,subs=+quotes]
----
[kafka@RHEL ~]$ cd /opt/kafka
[kafka@RHEL ~]$ unzip amq-streams-1.1.0-bin.zip
----

= Upgrading Kafka brokers and client applications to Kafka 2.1.1

After you have upgraded to {ProductName} 1.1.0, you can upgrade all Kafka brokers and client applications (consumers and producers) to Kafka 2.1.1. As shown in the following table, Kafka 2.1.1 uses a higher inter-broker protocol version and log message format version than Kafka 2.0.0.

[options="header"]
|=======================
|{ProductName} version |Kafka version |Inter-broker protocol version  |Log message format version | Zookeeper version
|1.0                   |2.0.0         |2.0                           |2.0                        | 3.4.13
|1.1.0                 |2.1.1         |2.1                           |2.1                        | 3.4.13
|=======================

= Downgrading Kafka brokers to the previous inter-broker protocol and message format versions

Manually configure and restart all the Kafka brokers in your cluster to use the previous inter-broker protocol and message format versions (2.0), and then test performance. 

NOTE: To avoid cluster downtime, update and restart the Kafka brokers one-by-one. 

.Prerequisites

* You have upgraded to {ProductName} 1.1.0.

.Procedure

. In a text editor, open the broker properties file for the Kafka broker you want to update first. These files are commonly stored in the `/opt/kafka/config/` directory.

. Temporarily override the default inter-broker protocol and message format versions for Kafka 2.0.0 by adding the following new properties to the file:
+
[source,shell,subs=+quotes]
----
inter.broker.protocol.version=2.0
log.message.format.version=2.0
----
+
This configures the Kafka broker to process data using the previous inter-broker protocol and log message format versions.

. On the command line, restart the Kafka broker:
+
[source,shell,subs=+quotes]
----
/opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties
----
+
NOTE: The broker will start using the version 1.1.0 JAR files.

. Repeat steps 1 through 3 for all Kafka brokers in your cluster.

. When all Kafka brokers are updated, test the performance of the cluster.

= Updating Kafka brokers to the new inter-broker protocol version

If cluster performance testing was successful, manually configure and restart all the Kafka brokers to use the new inter-broker protocol version (2.1). After performing these steps, data will be transmitted between the Kafka brokers using inter-broker protocol version 2.1. Messages received are still appended to the message logs in message format version 2.0. 

WARNING: Downgrading to {ProductName} 1.0.0 is not possible after completing this procedure.

NOTE: To avoid downtime, update and restart the Kafka brokers one-by-one.

.Prerequisites
* You have upgraded to {ProductName} 1.1.0.
* You have downgraded Kafka brokers to use the previous inter-broker protocol and message format versions (2.0) and tested performance.

.Procedure

. In a text editor, open the broker properties file for the Kafka broker you want to update first. These files are commonly stored in the `/opt/kafka/config/` directory.

. Set the `inter.broker.protocol.version` to `2.1`.

. On the command line, restart the Kafka broker:
+
[source,shell,subs=+quotes]
----
/opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties
----

. Repeat steps 1 through 3 for all Kafka brokers in your cluster.

= Upgrading client applications to the new Kafka version

Upgrade consumers and producers to use {ProductName} 1.1.0. Red Hat recommends that you upgrade consumers first, as described in the following procedure.

.Prerequisites

* You have upgraded to {ProductName} 1.1.0.
* You have downgraded Kafka brokers to use the previous inter-broker protocol and message format versions (2.0) and tested performance.
* You have updated Kafka brokers to use the new inter-broker protocol version (2.1).

.Procedure

. Upgrade all consumers to use version 1.1.0 of the {ProductName} client libraries.

. Optional: To avoid a temporary potential loss of performance in the cluster, perform the following steps. Otherwise, go to step three.

.. Set the message format version on a topic-by-topic basis for each producer. This avoids messages received by the Kafka brokers from being converted down to message format version 2.0, which is likely to increase CPU usage and affect cluster performance.
+
On the command line, set the `message.format.version` configuration option to `2.1` for the topic that you want to update first.
+
[source,shell,subs=+quotes]
----
bin/kafka-configs.sh --zookeeper _<ZookeeperAddress>_ --entity-type topics --entity-name <TopicName> --alter --add-config message.format.version=2.1
----

.. Identify the producer or producers that write data to the topic you modified in step 2a, and then upgrade them to use message format version 2.1.

.. Repeat steps a and b for all topics in your cluster, and for all producers.

. Optional: If you did not complete step two, upgrade all producers to use message format version 2.1.
+
NOTE: Unless you performed step two, messages sent by producers to topics are now converted down to message format version 2.0 before being appended to the message logs. This is likely to cause performance loss in the cluster. To restore normal performance, update all Kafka brokers to use message format version 2.0 as soon as possible. For details, see XREF Updating Kafka brokers to use the new log message format version.

= Updating Kafka brokers to the new message format version

When client applications have been upgraded, you can update the Kafka brokers to use the new message format version (2.1). 

NOTE: To avoid downtime, update and restart the Kafka brokers one-by-one.

.Prerequisites
* You have upgraded to {ProductName} 1.1.0
* You have downgraded Kafka brokers to use the previous inter-broker protocol and message format versions and tested performance.
* You have updated Kafka brokers to use the new inter-broker protocol version.
* You have upgraded client applications to the new Kafka version.

.Procedure

. In a text editor, open the broker properties file for the Kafka broker you want to update first. These files are commonly stored in the `/opt/kafka/config/` directory.

. Set the `log.message.format.version` to 2.1.

. On the command line, restart the Kafka broker:
+
[source,shell,subs=+quotes]
----
/opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties
----

. Repeat steps 1 through 3 for all Kafka brokers in your cluster.